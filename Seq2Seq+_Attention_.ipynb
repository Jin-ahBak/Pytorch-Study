{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2Seq+ Attention .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jin-ahBak/Pytorch-Study/blob/master/Seq2Seq%2B_Attention_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feKCH-Xbr22N"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3npH51t8tMg4",
        "outputId": "4ed02d80-9043-42b9-c75d-17712a575a1e"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A73XBkCr22R"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9R3B2xOHI9a"
      },
      "source": [
        "# 기계 번역 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SapxBVjHNYB"
      },
      "source": [
        "* Seq2Seq에는 **인코더의 입력, 디코더의 입력, \n",
        "디코더의 출력** 에 해당하는 데이터가 필요\n",
        "*   목표 데이터에는 시작과 끝을 나타내는 토큰이 포함되어야 함\n",
        "*   여기서는 '\\t'와 '\\n'을 각각 시작과 끝을 나타내는 토큰으로 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2VkcWatNMMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc318f5c-e11b-45ab-9147-0ee94232cdb5"
      },
      "source": [
        "lines = pd.read_csv('/content/drive/MyDrive/fra.txt', names = ['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']  \n",
        "len(lines)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190206"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "t4plNaEhr22W",
        "outputId": "c0f56ece-fc31-45cc-f61e-85b66439a79b"
      },
      "source": [
        "lines = lines.loc[:, 'src': 'tar']  \n",
        "\n",
        "lines = lines[0:60000]  \n",
        "\n",
        "lines.tar = lines.tar.apply(lambda x:'\\t' + x + '\\n')    \n",
        "\n",
        "lines[:10]\n",
        "lines.sample(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18285</th>\n",
              "      <td>I like traveling.</td>\n",
              "      <td>\\tJ'aime voyager.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33996</th>\n",
              "      <td>He accepted the job.</td>\n",
              "      <td>\\tIl a accepté le job.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52265</th>\n",
              "      <td>Whose handbag is this?</td>\n",
              "      <td>\\tÀ qui est ce sac à main ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48168</th>\n",
              "      <td>I helped fix the leak.</td>\n",
              "      <td>\\tJ'ai aidé à réparer la fuite.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23843</th>\n",
              "      <td>I will do my best.</td>\n",
              "      <td>\\tJe vais faire de mon mieux.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25769</th>\n",
              "      <td>Tom fed the horse.</td>\n",
              "      <td>\\tTom donna à manger au cheval.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>What a drag!</td>\n",
              "      <td>\\tQuel boulet !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51744</th>\n",
              "      <td>We were all disgusted.</td>\n",
              "      <td>\\tNous étions toutes dégoûtées.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20099</th>\n",
              "      <td>They were killed.</td>\n",
              "      <td>\\tIls ont été assassinés.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2038</th>\n",
              "      <td>I'm a twin.</td>\n",
              "      <td>\\tJ'ai un jumeau.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          src                                tar\n",
              "18285       I like traveling.                \\tJ'aime voyager.\\n\n",
              "33996    He accepted the job.           \\tIl a accepté le job.\\n\n",
              "52265  Whose handbag is this?      \\tÀ qui est ce sac à main ?\\n\n",
              "48168  I helped fix the leak.  \\tJ'ai aidé à réparer la fuite.\\n\n",
              "23843      I will do my best.    \\tJe vais faire de mon mieux.\\n\n",
              "25769      Tom fed the horse.  \\tTom donna à manger au cheval.\\n\n",
              "4093             What a drag!                  \\tQuel boulet !\\n\n",
              "51744  We were all disgusted.  \\tNous étions toutes dégoûtées.\\n\n",
              "20099       They were killed.        \\tIls ont été assassinés.\\n\n",
              "2038              I'm a twin.                \\tJ'ai un jumeau.\\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2DHfeeSOsAo"
      },
      "source": [
        "\n",
        "\n",
        "*   해당 예제에서는 글자 단위로 예측, 따라서 글자 집합을 구축해주어야 함\n",
        "*   구축한 다음, 정렬해 인덱스를 부여해 글자에 해당하는 사전을 만듬\n",
        "*   사전은 글자를 모델에 투입하도록 변환하거나 예측시 반환되는 인덱스들을 글자로 변환할 때 사용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T18GljqANlT1"
      },
      "source": [
        "##### 글자 단위로 예측하기에 글자집합 구축 \n",
        "\n",
        "src_vocab = set()  \n",
        "for line in lines.src: # 1줄씩 읽음 \n",
        "    for char in line:  # 1개의 글자씩 읽음 \n",
        "        src_vocab.add(char)  \n",
        "        \n",
        "\n",
        "tar_vocab = set()  \n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)  \n",
        "        "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCIiItcXNoEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6c585e-287c-4ba1-b7b1-65d7d2e4590b"
      },
      "source": [
        "###### 정렬해 인덱스를 부여함 \n",
        "src_vocab = sorted(list(src_vocab))  \n",
        "tar_vocab = sorted(list(tar_vocab))  \n",
        "\n",
        "src_vocab_size = len(src_vocab) + 1 \n",
        "tar_vocab_size = len(tar_vocab) + 1   \n",
        "\n",
        "\n",
        "#### 딕셔너리 형태로 만듦.\n",
        "src_to_idx = dict([(word, i+1) for i, word in enumerate(src_vocab)])  \n",
        "print(src_to_idx)  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-DKhfelr22a",
        "outputId": "9f813a18-0ee3-4376-c470-3929088444b6"
      },
      "source": [
        "tar_to_idx = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "\n",
        "print(tar_to_idx)  "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flh0swsdPOhc"
      },
      "source": [
        "*   인코더에 입력될 입력 데이터를 구성\n",
        "*   문장의 글자 하나씩을 사전을 이용해 인덱스로 변환해 리스트에 넣음\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgtp58H-NpBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1576f2c9-7c96-4c03-a8bc-c22fd8509baf"
      },
      "source": [
        "### 인코더 입력값  \n",
        "\n",
        "encoder_input = []  \n",
        "for line in lines.src: # 입력데이터에서 1줄씩 문장을 읽음 \n",
        "    encoder_input.append([src_to_idx[w] for w in line]) # 각 줄에서 1개씩 문자 읽고 글자에 해당되는 정수로 변환 \n",
        "    \n",
        "print(encoder_input[:5])\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agsrqdb7PQP5"
      },
      "source": [
        "\n",
        "\n",
        "*   디코더에 입력될 입력 데이터를 구성\n",
        "*   인코더 입력 데이터 처리와 동일하나, 목표 데이터에 해당하는 사전을 사용해주어야 함\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffnswHwUr22c",
        "outputId": "73153cf0-d1df-4c85-aabb-3d10699db95a"
      },
      "source": [
        "### 디코더 입력값 \n",
        "\n",
        "decoder_input = []  \n",
        "for line in lines.tar:\n",
        "    decoder_input.append([tar_to_idx[w] for w in line])\n",
        "    \n",
        "print(decoder_input[:5])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 48, 53, 3, 4, 2], [1, 39, 53, 70, 55, 60, 57, 14, 2], [1, 28, 67, 73, 59, 57, 3, 4, 2], [1, 45, 53, 64, 73, 72, 3, 4, 2], [1, 45, 53, 64, 73, 72, 14, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOCf-xuEPSm1"
      },
      "source": [
        "\n",
        "*   디코더의 출력과 비교할 목표 데이터를 구성\n",
        "*   디코더의 입력 데이터를 구성할 때와 동일하나, 시작 토큰을 제외해주어야 함\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KogHdxHsNrl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d8446b-30e4-4a10-fbf6-81cb1608465d"
      },
      "source": [
        "### 디코더 실제값 = 목표 데이터 = 디코더의 입력데이터와 동일(단, 시작토큰 \\t 제외)\n",
        "\n",
        "decoder_target = []  \n",
        "for line in lines.tar:\n",
        "    decoder_target.append([tar_to_idx[w] for w in line if w != '\\t'])\n",
        "    \n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[48, 53, 3, 4, 2], [39, 53, 70, 55, 60, 57, 14, 2], [28, 67, 73, 59, 57, 3, 4, 2], [45, 53, 64, 73, 72, 3, 4, 2], [45, 53, 64, 73, 72, 14, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a5A0lzdPWad"
      },
      "source": [
        "\n",
        "\n",
        "* 각각의 데이터를 동일한 길이로 맞춰줌\n",
        "* 길이를 맞춰줄 때는 해당 데이터의 최대 길이로 맞춰줌\n",
        "* 원 핫 인코딩을 통해 원 핫 벡터로 변환\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BAyplv9Nuan"
      },
      "source": [
        "##### 최대길에 맞춰서 패딩( 데이터를 동일한 길이로 맞춰줌)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
        "\n",
        "max_src_len = max([len(line) for line in lines.src])  \n",
        "max_tar_len = max([len(line) for line in lines.tar])  \n",
        "\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urrwjhZhNvse"
      },
      "source": [
        "## categorical한 one-hot-vector로 변경 \n",
        "\n",
        "from tensorflow.keras.utils import to_categorical  \n",
        "\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWvb8olj_6DN"
      },
      "source": [
        "# Attention Mechanism\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkrszocaIMgk"
      },
      "source": [
        "* Attention Mechanism은 디코더가 예측하는 시점마다 인코더의 전체 입력 문장을 다시 한번 참조\n",
        "* 이때 전체 입력 문장을 단순히 참조하지 않고, **예측할 단어와 연관이 있는 단어를 집중(Attention)**해서 참조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mE8cK9ZIme-"
      },
      "source": [
        "## Attention Mechanism 종류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9qGhZFoqav6"
      },
      "source": [
        "* attention mechanism에는 스코어 계산 방식의 차이에 따라 다양한 종류가 존재\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMgyQdwOI75i"
      },
      "source": [
        "이 름                 | 스 코 어&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                 \n",
        "----------------------|-----------------------\n",
        "dot|$score(s_t, h_i) = s_t^Th_i$\n",
        "scaled dot|$score(s_t, h_i) = \\frac{s_t^Th_i}{\\sqrt n}$\n",
        "general|$score(s_t, h_i) = s_t^TW_ah_i$\n",
        "concat|$score(s_t, h_i) = W_a^Ttanh(W_b[s_t;h_i])$\n",
        "location-base|$a_t = softmax(W_as_t)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL2wrixdqboQ"
      },
      "source": [
        "  + $s_t$ : querys(t 시점에서의 디코더 셀의 은닉 상태)\n",
        "  + $h_i$ : keys(모든 시점의 인코더 셀 은닉 상태)\n",
        "  + $W_a, W_b$ : 학습 가능한 가중치 행렬\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTILo0WuIub1"
      },
      "source": [
        "## Attention Mechanism 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swVCCTreIysk"
      },
      "source": [
        "* Attention Mechanism 과정\n",
        "  1. encoder/ decoder Embedding과 LSTM 레이어 생성\n",
        "  1. attention score 계산\n",
        "  2. 소프트맥스 함수를 통한 attention distribution 계산\n",
        "  3. 각 인코더의 (어텐션 가중치)와 (은닉 상태)를 가중합하여= 내적하여 어텐션 값 계산\n",
        "  4. (어텐션 값)과 (디코더의 t 시점의 은닉 상태)를 연결\n",
        "  5. 출력층 연산의 입력이 되는 $\\tilde{s}_t$ 계산\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk8s2ESIpE8G"
      },
      "source": [
        "### Attention score 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPM6gjyFpIH3"
      },
      "source": [
        "### 소프트 맥스 함수를 통한 attention distribution 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7__vtckPpMAC"
      },
      "source": [
        "### 각 인코더의 어텐션 가중치와 은닉 상태를 가중합해 어텐션 값 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_acjI-epQPv"
      },
      "source": [
        "### 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da60zEX3r22h"
      },
      "source": [
        "![전체구조](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FIcOuI%2Fbtq9eM78HJe%2Fu6WeljAakJGQCwJvzfIHPK%2Fimg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R_2m-DuJ7-E"
      },
      "source": [
        "## Attention Mechanism 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbbdF6YXkdF9"
      },
      "source": [
        "### 인코더(Encoder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GH8IwyfkXKj"
      },
      "source": [
        "\n",
        "\n",
        "*   인코더는 seq2seq에서 작성한 것과 동일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w_12MxSuoHF"
      },
      "source": [
        "from keras.layers import Input, LSTM  \n",
        "\n",
        "\n",
        "# encoding에  return_sequences= True추가( 인코더 내부상태를 디코더로 넘겨줌) \n",
        "# LSTM의 은닉 상태 크기는 256로 선택\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))  \n",
        "encoder_lstm = LSTM(256, return_state= True)  \n",
        "\n",
        "# LSTM은 state가 2개: hidden과 cell state 를 디코더로 전달\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)  \n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTlrYMOcr22i"
      },
      "source": [
        "-- hidden state는 계층의 출력 / 다음 타임 step 으로 넘기는 정보  \n",
        "-- cell state는 기억을 오랫동안 유지할 수 있는 구조/ 새로운 특징을 덧셈으로 받는 구조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4ouiqAUr22i"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "그렇게 하면 Encoder의 LSTM은 I, LOVE, YOU 3단어를 입력받고 3개의 값을 출력한다.\n",
        "\n",
        "그리고 Decoder의 LSTM에게 hidden state와, cell state를 넘겨준다.\n",
        "\n",
        "Encoder에서 넘긴 state들은 encoder에서 압축된 \"I love you\"의 문맥과 의미 정보를 Decoder에 제공한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6kIEuiokezL"
      },
      "source": [
        "### 디코더(Decoder) + Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDROkM8Ikn1k"
      },
      "source": [
        "\n",
        "\n",
        "*   디코더에서는 seq2seq와는 다르게 **attention layer를 추가함**\n",
        "*   S_는 은닉 상태와 디코더의 최종 출력을 연결한 결과, 연결할 때 형상을 맞춰주기 위해 축을 추가함\n",
        "*   attention layer는 디코더의 은닉 상태와 인코더 은닉 상태 전체를 받아 컨텍스트 벡터를 생성함\n",
        "*   이 때 attention layer는 앞서 설명한 과정 중 1~3번째를 수행, 나머지는 사용자가 연결해주어야 함\n",
        "*   마지막으로 생성한 컨텍스트 벡터와 디코더의 은닉 상태 전체를 이어 softmax layer에 투입, 인덱스를 예측함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuVVq4Sur22i"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQhlf6ytr22j"
      },
      "source": [
        "import tensorflow as tf  \n",
        "# Decoder 내부또한 Embedding 레이어와 LSTM레이어로 이루어짐.\n",
        "\n",
        "decoder_inputs = Input(shape=(None, tar_vocab_size))  \n",
        "decoder_lstm = LSTM(256, return_sequences = True, return_state= True)    \n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states) \n",
        "\n",
        "\n",
        "# concat해주는 S_ : hidden과 디코더 output 합쳐야함.  \n",
        "# score 계산하는 부분 히든레이어에 decoder outputs\n",
        "\n",
        "S_ = tf.concat([state_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis= 1)  "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7l484Nnr22j"
      },
      "source": [
        "from keras.layers import Dense\n",
        "from keras.layers import Attention\n",
        "\n",
        "# 어텐션 \n",
        "attention = Attention()\n",
        "\n",
        "# 어텐션 값 = (어텐션 가중치 * 인코더의 결과값( 은닉상태))  = context_vector  \n",
        "context_vector = attention([S_, encoder_outputs])  \n",
        "\n",
        "# context_vector와 디코더의 은닉상태 연결 \n",
        "concat = tf.concat([decoder_outputs, context_vector], axis= -1)\n",
        "\n",
        "# softmax layer에 투입하여 인덱스 예측 \n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')  \n",
        "decoder_outputs = decoder_softmax_layer(concat)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5i84VCLkhzz"
      },
      "source": [
        "### 모델 구성 및 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRjWvXBnlUdE"
      },
      "source": [
        "\n",
        "\n",
        "*   구성하는 방법은 seq2seq와 동일함\n",
        "*   **attention mechanism을 활용해 학습 시간이 절반 가량 준 것을 확인할 수 있음**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-88uJ1MgvLY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7174cdf5-83d3-48f3-c07e-40a3e0d4b67b"
      },
      "source": [
        "from keras.models import Model  \n",
        "\n",
        "# 모델생성\n",
        "model= Model([encoder_inputs, decoder_inputs], decoder_outputs)  \n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=['acc'])   # 옵티마이저와 손실함수 선택 \n",
        "\n",
        "# 모델검증\n",
        "model.fit(x=[encoder_input, decoder_input], y= decoder_target,\n",
        "         batch_size= 128,\n",
        "          epochs= 25,\n",
        "          validation_split = 0.2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "375/375 [==============================] - 29s 69ms/step - loss: 0.8959 - acc: 0.7629 - val_loss: 0.8169 - val_acc: 0.7603\n",
            "Epoch 2/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.5518 - acc: 0.8372 - val_loss: 0.6428 - val_acc: 0.8080\n",
            "Epoch 3/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.4595 - acc: 0.8625 - val_loss: 0.5710 - val_acc: 0.8293\n",
            "Epoch 4/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.4051 - acc: 0.8783 - val_loss: 0.5217 - val_acc: 0.8442\n",
            "Epoch 5/25\n",
            "375/375 [==============================] - 25s 65ms/step - loss: 0.3690 - acc: 0.8887 - val_loss: 0.4863 - val_acc: 0.8549\n",
            "Epoch 6/25\n",
            "375/375 [==============================] - 24s 65ms/step - loss: 0.3460 - acc: 0.8954 - val_loss: 0.4621 - val_acc: 0.8611\n",
            "Epoch 7/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.3245 - acc: 0.9017 - val_loss: 0.4430 - val_acc: 0.8676\n",
            "Epoch 8/25\n",
            "375/375 [==============================] - 25s 65ms/step - loss: 0.3077 - acc: 0.9066 - val_loss: 0.4281 - val_acc: 0.8720\n",
            "Epoch 9/25\n",
            "375/375 [==============================] - 24s 65ms/step - loss: 0.2953 - acc: 0.9101 - val_loss: 0.4162 - val_acc: 0.8755\n",
            "Epoch 10/25\n",
            "375/375 [==============================] - 25s 65ms/step - loss: 0.2838 - acc: 0.9134 - val_loss: 0.4066 - val_acc: 0.8787\n",
            "Epoch 11/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2738 - acc: 0.9164 - val_loss: 0.4012 - val_acc: 0.8803\n",
            "Epoch 12/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2648 - acc: 0.9188 - val_loss: 0.3961 - val_acc: 0.8813\n",
            "Epoch 13/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2571 - acc: 0.9211 - val_loss: 0.3915 - val_acc: 0.8833\n",
            "Epoch 14/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2500 - acc: 0.9231 - val_loss: 0.3889 - val_acc: 0.8846\n",
            "Epoch 15/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2436 - acc: 0.9251 - val_loss: 0.3851 - val_acc: 0.8860\n",
            "Epoch 16/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2376 - acc: 0.9268 - val_loss: 0.3850 - val_acc: 0.8862\n",
            "Epoch 17/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2321 - acc: 0.9284 - val_loss: 0.3811 - val_acc: 0.8875\n",
            "Epoch 18/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2270 - acc: 0.9299 - val_loss: 0.3789 - val_acc: 0.8885\n",
            "Epoch 19/25\n",
            "375/375 [==============================] - 25s 67ms/step - loss: 0.2222 - acc: 0.9313 - val_loss: 0.3785 - val_acc: 0.8890\n",
            "Epoch 20/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2177 - acc: 0.9328 - val_loss: 0.3774 - val_acc: 0.8897\n",
            "Epoch 21/25\n",
            "375/375 [==============================] - 24s 65ms/step - loss: 0.2133 - acc: 0.9340 - val_loss: 0.3783 - val_acc: 0.8896\n",
            "Epoch 22/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2092 - acc: 0.9352 - val_loss: 0.3793 - val_acc: 0.8904\n",
            "Epoch 23/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2054 - acc: 0.9364 - val_loss: 0.3798 - val_acc: 0.8903\n",
            "Epoch 24/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.2017 - acc: 0.9375 - val_loss: 0.3766 - val_acc: 0.8913\n",
            "Epoch 25/25\n",
            "375/375 [==============================] - 25s 66ms/step - loss: 0.1981 - acc: 0.9386 - val_loss: 0.3787 - val_acc: 0.8911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f4541b710>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-huw5tCP3hWM"
      },
      "source": [
        "### 예측\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqAhmptVjjvm"
      },
      "source": [
        "###  전체적인 번역 동작단계 \n",
        "1. 번역하고자 하는 입력문장이 encoder에 들어가 hidden state 와 cell state 얻음\n",
        "2. state와 <SOS> 에 해당하는 '\\t'를 decoder로 보냄\n",
        "3. decoder가 <EOS> 에 해당하는 '\\n'이 나올떄까지 다음 문자 예측 행동 반복 \n",
        "\n",
        "    \n",
        "*   예측도 seq2seq와 동일하나, 추가된 모델 구조를 반영해주어야 함(attention layer)\n",
        "*   encoder와 decoder를 분리해주었기 때문에 디코더에서 인코더의 은닉 상태(estate_h)=( encoder states)와 최종 은닉 상태(encoder_outputs)를 따로 입력받아야 함\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evrcagqfr22k"
      },
      "source": [
        "# 인코더 모델\n",
        "encoder_model = Model(inputs= encoder_inputs, \n",
        "                      outputs = [encoder_outputs, encoder_states])\n",
        "\n",
        "\n",
        "# 인코더 디코더 input , output 값 변수생성 \n",
        "decoder_state_input_h = Input(shape=(256))  \n",
        "decoder_state_input_c = Input(shape=(256)) \n",
        "estate_h = Input(shape=(256))  \n",
        "encoder_outputs = Input(shape=(256))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]  \n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)  \n",
        "decoder_states = [state_h, state_c]  \n",
        "S_ = tf.concat([state_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis= 1)  \n",
        "context_vector = attention([S_, encoder_outputs]) \n",
        "decoder_concat = tf.concat([decoder_outputs, context_vector], axis= -1)  \n",
        "decoder_outputs = decoder_softmax_layer(decoder_concat)  \n",
        "\n",
        "\n",
        "# 디코더 모델 \n",
        "decoder_model = Model(inputs=[decoder_inputs, estate_h, encoder_outputs] + decoder_state_inputs,\n",
        "                     outputs=[decoder_outputs]+ decoder_states)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGXAHGd8r22k"
      },
      "source": [
        "# 인덱스로부터 단어를 얻는 dictionary \n",
        "\n",
        "idx_to_src = dict((i, char) for char, i in src_to_idx.items())  \n",
        "idx_to_tar = dict((i, char) for char, i in tar_to_idx.items()) "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i6nyNCbamz_"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_decode(input_seq):\n",
        "    # 입력으로부터 인코더의 상태얻음\n",
        "    outputs_input, states_value = encoder_model.predict(input_seq)  \n",
        "    \n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성 \n",
        "    target_seq = np.zeros((1,1,tar_vocab_size))  \n",
        "    target_seq[0,0,tar_to_idx['\\t']] = 1  \n",
        "    \n",
        "\n",
        "    stop = False  \n",
        "    decoded_sentence = \"\"  \n",
        "\n",
        "    # stop이 True가 될때까지 루프 반복 = 즉, end될때까지 번역하는 반복문 \n",
        "    while not stop:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq,states_value[0], outputs_input] + states_value)  \n",
        "        \n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])  \n",
        "        sampled_char = idx_to_tar[sampled_token_index]  \n",
        "        \n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가 \n",
        "        decoded_sentence += sampled_char  \n",
        "        \n",
        "        # <EOS> 에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if sampled_char == '\\n' or len(decoded_sentence) > max_tar_len:  \n",
        "            stop = True  \n",
        "            \n",
        "        # 현재 시점의 예측결과를 다음 시점의 입력으로 사용하기 위해 저장 \n",
        "        target_seq = np.zeros((1,1, tar_vocab_size))  \n",
        "        target_seq[0,0,sampled_token_index] =1.\n",
        "        states_value = [h,c]  \n",
        "    return decoded_sentence  \n",
        "    "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvQNB_ljairY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936cdae9-d4db-4b98-b2c7-33ff8a4118c1"
      },
      "source": [
        "for seq_index in [39098, 29027, 32825, 27062, 39277]: # 입력 문장의 인덱스 무작위 선정 \n",
        "    input_seq = encoder_input[seq_index : seq_index+1]  \n",
        "    decoded_sentence = predict_decode(input_seq)  \n",
        "    \n",
        "    print('입력:' , lines.src[seq_index])  \n",
        "    print('정답:' , lines.tar[seq_index][1:len(lines.tar[seq_index])-1])  # '\\t'와 '\\n' 을 뺴고 출력 \n",
        "    print('번역:' , decoded_sentence[:len(decoded_sentence)-1], '\\n')  # '\\n'을 뺴고 출력 "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력: You're a clever kid.\n",
            "정답: Tu es un enfant intelligent.\n",
            "번역: Vous êtes un bon garçon. \n",
            "\n",
            "입력: I know your father.\n",
            "정답: Je connais ton père.\n",
            "번역: Je sais que tu es intelligent. \n",
            "\n",
            "입력: You look very pale.\n",
            "정답: Vous avez l'air très pâle.\n",
            "번역: Tu as l'air déprimée. \n",
            "\n",
            "입력: You never gave up.\n",
            "정답: Vous n'avez jamais abandonné.\n",
            "번역: Vous avez été impressionnée. \n",
            "\n",
            "입력: Your friend is here.\n",
            "정답: Votre amie est ici.\n",
            "번역: Ton amie est deux foulles. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3XLoj3kJU0"
      },
      "source": [
        "\n",
        "\n",
        "*   seq2seq와 동일한 문장을 번역\n",
        "*   seq2seq에 비해 좀 더 나은 성능을 보여줌\n",
        "\n"
      ]
    }
  ]
}